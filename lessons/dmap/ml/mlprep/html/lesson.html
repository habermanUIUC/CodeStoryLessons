<!DOCTYPE html><html lang='en'><head><title>Machine Learning</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}input{font-family:inherit;font-size:100%;line-height:1.15;margin:0}input{overflow:visible}[type=checkbox]{box-sizing:border-box;padding:0}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}blockquote,h1,h2,h3,h4,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}input:-ms-input-placeholder{color:#a0aec0}input::-ms-input-placeholder{color:#a0aec0}input::-moz-placeholder{color:#a0aec0}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}input{padding:0;line-height:inherit;color:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-orange-300{--bg-opacity:1;background-color:#fbd38d;background-color:rgba(251,211,141,var(--bg-opacity))}.bg-green-200{--bg-opacity:1;background-color:#c6f6d5;background-color:rgba(198,246,213,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.border-indigo-500{--border-opacity:1;border-color:#667eea;border-color:rgba(102,126,234,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border{border-width:1px}.border-l-2{border-left-width:2px}.border-t{border-top-width:1px}.cursor-pointer{cursor:pointer}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-right{float:right}.float-left{float:left}.clearfix:after{content:"";display:table;clear:both}.clear-both{clear:both}.font-sans{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-none{line-height:1}.leading-normal{line-height:1.5}.m-2{margin:.5rem}.my-3{margin-top:.75rem;margin-bottom:.75rem}.mt-0{margin-top:0}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.ml-3{margin-left:.75rem}.mt-4{margin-top:1rem}.mb-4{margin-bottom:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.opacity-0{opacity:0}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.p-3{padding:.75rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.absolute{position:absolute}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-2\/3{width:66.666667%}.w-full{width:100%}@media (min-width:768px){.md\:w-2\/3{width:66.666667%}}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.main-content{max-width:900px}.lesson{padding-left:15px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.main-content,html{font-family:Arial,Georgia,Verdana,"Times New Roman"!important}.lesson-footer-card,.lesson-overview-card{font-family:"Times New Roman"!important}blockquote em:first-child{font-family:Times!important;font-size:1.35em;margin-right:10px}blockquote em:first-child:after{content:":"}.lesson-footer{margin-top:50px;margin-top:20px}li>p{display:inline!important}.lesson ol{list-style-type:decimal;list-style-position:inside;margin-left:1em}.lesson ul{list-style-position:inside;list-style-type:none;margin-left:1em}.lesson ul li{padding-left:1em;padding-right:5px}.lesson ul li::before{content:"‚Ä¢";padding-right:5px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em}p.new+p{padding-top:.5em}h1,h2,h3,h4{font-weight:700;margin-top:.25em!important;margin-bottom:.05em!important;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{font-size:2em!important;clear:both;color:#000!important}div+h1,h2{margin-top:0!important}h2{margin-top:.5em!important;font-size:1.5em!important;clear:both;color:#8b0000!important}h3{font-size:1.25em!important;clear:both;color:#006400!important}h4{font-size:1em!important;clear:both;color:#00008b!important}ul{margin-bottom:30px}p.new a{text-decoration:underline}.lesson a{text-decoration:underline;color:#00f}.title-text{font-size:2rem}blockquote{font-size:1em;background:#f9f9f9;border-left:10px solid #ccc;margin:.5em 10px;padding:.5em 10px;border-left-color:#ffcd69;border-right-color:#f6ba59;quotes:"\201C""\201D""\2018""\2019"}blockquote:before{color:#ccc;content:open-quote;font-size:4em;line-height:.1em;margin-right:.25em;vertical-align:-.4em}blockquote:after{color:#ccc;content:no-close-quote}blockquote p{display:inline}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}img.center{-o-object-position:center;object-position:center;margin-left:auto;margin-right:auto}img.border{border:1px solid #021a40;margin-top:.5rem;margin-bottom:.75rem}img.iw600{height:auto;width:auto;max-width:600px}img.iw400{height:auto;width:auto;max-width:400px}img.iw300{height:auto;width:auto;max-width:300px}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:840px;max-width:840px;overflow:scroll;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}.tab{font-size:1rem;border-color:#8c6728}.tab-content{max-height:0;max-width:100%;transition:max-height .35s}.tab input:checked~.tab-content{max-height:100vh}.tab input:checked+label{padding:1rem;border-left-width:2px;border-color:#6574cd;background-color:#f8fafc;color:#6574cd}.tab label::after{float:right;right:0;top:0;display:block;width:1em;height:1.5em;line-height:1.5;font-size:1rem;text-align:center;transition:all .35s}.tab input[type=checkbox]+label::after{content:"+";font-weight:700;border-width:1px;border-radius:9999px;border-color:#8c6728}.tab input[type=checkbox]:checked+label::after{transform:rotate(315deg);background-color:#6574cd;color:#f8fafc}</style>
<script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script>
<script>
    let stateCheck = setInterval(function(){
      if (document.readyState === 'complete') {
        clearInterval(stateCheck);
        let s1 = document.getElementById('start');
        // console.log('doc is ready', s1);
        if (s1) {
           s1.setAttribute('tabindex', '-1');
           s1.focus(); 
           s1.scrollIntoView({behavior: 'smooth'}); 
           setTimeout(function(){s1.blur()}, 500);
           // console.log('focus set');
        }
      }
    }, 200);
    </script>
</head><body class="lesson"><div class="main-content lesson bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<div id="start" class="section">&nbsp;</div><h1 class="overview"></h1><div class="lesson-overview bg-gray-200 flex justify-center"><div class="text-center px-4 py-2 m-2"><div class="lesson-overview-card displaycard bg-blue-200 max-w-sm rounded overflow-hidden shadow-lg"><div>¬†</div><img alt="Text" class="object-contain h-64 w-full" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/MachineLearningV1-sm.png"/><div class="px-6 py-4"><div class="title-text text-center leading-none font-bold text-xl">Machine Learning</div><p class="text-center mt-2 text-gray-800 text-xl">Prepping for ML</p><div class="text-gray-700 text-base">¬†</div><div class="text-center mb-3"><span class="inline-block bg-gray-300 rounded-full px-3 py-1 text-sm font-semibold text-gray-700 mr-2">#machine learning</span></div><div class="flex border-t border-solid border-gray-500 shadow-inner justify-around bg-blue-300"><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap">D.M. &amp; the üêç</span></div><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap"><strong>Version:</strong> <!-- -->SP21</span></div></div><div class="text-gray-700 mt-1 text-center text-tiny">All Rights Reserved</div></div></div></div><div class="text-center px-4 py-2 m-2 w-1/2"><div class="displaycard bg-gray-200 max-w-sm rounded overflow-hidden shadow-lg"><div class="px-6 py-4 text-left"><div class="text-center font-bold text-xl">Machine Learning<br/><div><span>prerequisites</span><div class="text-center text-xs mb-2">(start only after finishing)</div><p class="max-w-sm text-gray-800 text-sm">‚¶ø <strong>info490</strong></p></div></div></div><div class="px-6 py-4 text-left text-gray-800"><div class="text-center font-bold text-xl">Colab Notes</div><p class="max-w-sm text-sm">1. <strong>Copy</strong> this notebook <img alt="copy2drive.png" class="inline-block" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/copy2drive.png"/></p><p class="max-w-sm text-sm">2. <strong>Update</strong> the <strong><code>NET_ID</code></strong> in the notebook</p><p class="max-w-sm text-gray-800 text-sm">3. <strong>Hit ‚ñ∂Ô∏è¬†</strong> to install the INFO 490 IDE</p><div class="text-center font-bold text-xl">¬†</div><div class="text-center font-bold text-xl">Jupyter/PyCharm Notes</div><p class="max-w-sm text-gray-800 text-sm text-left">The testing framework does <strong>not work</strong> (at this time) for Jupyter  notebooks or local code development.</p></div></div></div></div><h1 class="section" id="section1">Machine Learning</h1><p class="new">In the 80's (the previous century), <strong>AI</strong> (or artificial intelligence) was the 'hot ' 
word in technology.  In the 1990's and early 2000's, it was <strong>Data Mining</strong>. 
In 2010, anything around <strong>Data Science</strong> started to explode.  Today, 
it's <strong>Machine Learning</strong> (and its partner <strong>Deep Learning</strong>).  Much of all this 'hype' is actually
 closely related and this lesson attempts to unravel a bit of all the words you
 have most likely have heard -- but not quite sure how they all fit.</p><p class="new">Machine learning is filled with terminology and can become a bit overwhelming. 
These words and concepts will become more familiar as we repeat them when we are 
using specific algorithms. This lesson serves as an introduction to the ML 
mountain we are about to climb.</p><h2 id="a-new-model-for-programming">A new <em>model</em> for programming</h2><p class="new">Almost everything we have done so far has looked like the image below:</p><img alt="modelA.png" class="my-3 center border iw600" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/modelA.png"/><p class="new">That is, we, the data scientist, created a program (or a set of functions). 
That program is then given some data or input and it produces some output. </p><p class="new">The idea behind machine learning (ML for short) is that we still create a program
that is given data.  However, that program's output is another program (usually
called a model):
<img alt="modelB.png" class="my-3 center border iw600" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/modelB.png"/>That program/model is then given some input (new data) and then an 
answer/predication/output is produced. </p><h2 id="the-black-box-and-model-confusion">The Black Box and ‚ùì‚ùìModel‚ùì‚ùì Confusion</h2><img alt="blackBox.png" class="float-left border mr-3" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/blackBox.png"/><p class="new">In almost all cases, the output produced (the program) cannot be 'read' by 
a human to understand exactly what is happening; hence, it is usually referred to as 
a black box (something we aren't meant to see or understand). Neural networks 
(more about these later ) -- especially deep neural networks -- are notorious 
for being obtuse and impenetrable.</p><p class="new">The word 'model' is <em>usually</em> used to refer to this black box (the output of 
the ML algorithm).  However, the word 'model' is ALSO used to reference the
ML algorithm itself.  For example, you may read about 'how to select the 
best model' (a reference to the algorithm used) or how to train the model (a
 reference to the output produced) or as a reference to a specific mathematical 
 or probabilistic representation about the relationship between various 
 data attributes (a reference to the output).  We will attempt to use the word 
 model as a reference to the <strong>output of the ML algorithm</strong>. 
<br class="clear-both"/></p><h2 id="learning-from-data">Learning from Data</h2><p class="new">The word <strong>learning</strong> in this context means that the algorithm performs better
as more data is given to it.  There are many formal definitions of ML, but it 
basically means the performance improves (i.e. learns, makes less mistakes, 
has a lower error rate) with more experience.  Experience is based on seeing and
processing more data (or having more examples).  </p><blockquote><p class="new"><strong><em>ML Log</em></strong> Tom Mitchell (one of ML's pioneers) provides the following 
definition: <br/>‚ÄúA computer program is said to learn from experience E with respect to some class of 
tasks T and performance measure P, if its performance at tasks in T, as measured by P, 
improves with experience E.‚Äù</p></blockquote><p class="new">One of <em>the</em> most important aspects of ML is that the quality of the model 
generated depends almost entirely on both the quality and quantity of the
 data.  The term <strong>big data</strong> is just a reference to the fact that some of
  these algorithms need a lot of data to build an accurate model.  So much 
  data in fact, that understanding how to manage and use 'big data' has 
  emerged as a new sub-field and career path.</p><h3 id="training-the-model--learning">Training the Model == Learning</h3><p class="new">Many of the ML algorithms involve iterations through the same data.  After
the algorithm processes all the data, an evaluation is made as to it's
 performance (correctness, minimization of loss or risk).  Adjustments 
 are made (more on this later) and the process starts over. This process is usually referred as
  'training' the model.  It is how it "learns".  You may hear the word 'fitting' as well 
  to reference training and building the model -- which we will discuss soon.</p><h2 id="model-building-and-evaluation">Model Building and Evaluation</h2><img alt="ModelBuilding.png" class="border my-3 mr-3 float-left" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/ModelBuilding.png"/><p class="new">The image to the left presents an overview of the entire learning process.  The 
dataset is partitioned into a training and validation sets. The algorithm
uses the training set to <strong><em>fit</em> a model</strong> (fitting is synonymous with training). 
The output, the model, is then validated (sometimes called <em>transformed</em>) against a subset of the data 
that it was <strong>not</strong> trained on.  If the evaluation metrics are not 
within some pre established tolerance, the process repeats itself (a training <em>epoch</em>).</p><p class="new">You can think of the output of the ML algorithm as trying to find the best
fit to a set of parameters to the black box.  The evaluation/transform stage
is just using those parameters with the validation data.</p><p class="new">To make it even more confusing, some will call the validation dataset the
 <em>test</em> dataset.  The next section attempts to clarify the differences.</p><h2 id="model-selection">Model Selection</h2><img alt="ModelEvaluation.png" class="border mb-3 ml-3 iw300 float-right" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/ModelEvaluation.png"/><p class="new">There is also the idea of selecting the <em>best</em> model from different
 algorithms.  You may be able to solve a problem using different ML techniques or by building
different models with the same technique but with different parameter values (i.e. hyperparameters). 
In this case, a <em>test</em> dataset is used that will help in determining which model to use.  </p><p class="new">The splitting of data into training, validation and testing sets is a
 standard approach in machine learning. However, if you have a small dataset
 splitting the data into smaller sets is problematic.  A technique called
  cross-validation is used.  However, we will discuss the details of cross
  -validation later.</p><br/><h2 id="model-prediction-">Model Prediction </h2><img alt="modelPredict.png" class="border iw400 my-3 mr-3 center" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/modelPredict.png"/><p class="new">Once the model is built, trained and evaluated, it's time to use it.  The
 goal of most ML models is to offer some kind of prediction for the new data.
 Both the words 'predict' and 'transform' are used to reference the idea of
  pushing the new data through the model and hopefully end up with an accurate estimation/prediction.</p><h2 id="algorithm-selection-project-goals-and-data">Algorithm Selection: Project Goals And Data</h2><img alt="ML.png" class="inline mr-3 float-left" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/ML.png"/><p class="new">Much of our learning about ML (and teaching) involves trying to understand, 
organize and categorize the types of algorithms one can use to build a model.<br/>The selection of what type of ML algorithm to use can depend on both the
 goals of the project (e.g is it to predict?, group/cluster?, find patterns?) 
 and the available data to create and train the model.  We will 
 focus on the three most common categories of ML algorithms:  supervised, unsupervised, 
 and reinforcement learning.  You may have even come across these words
  several times.</p><h3 id="labeled-and-unlabeled-data">Labeled (and unlabeled) Data</h3><p class="new">Understanding the nature of the data has a major impact in what kind of machine 
learning can be done.  One of the important aspects is whether the
 data is 'labeled' or not.  For labeled data, the data itself has a field/attribute/column 
that identifies or 'labels' the data (sometimes referred to as the target).</p><h4 id="independent-and-dependent-variables">Independent and dependent variables</h4><p class="new">Another way to think about labeled data is if your data has a dependent
 variable.  As a quick reminder, the dependent variable is an observation or
  measurement whose value is affected by other influences (hopefully the
   captured independent variables).  This variable is the 'label'. For 
 example, if you had a database of images, each image could be 'labeled' that 
identifies the type of object/thing in the image.  The label could also
 indicate if the data has a specific characteristic or not.  As another
  example, if you had a list of borrowers' attributes for a loan program, your label 
might be whether or not a load was given to that person.  </p><p class="new">If you're trying to predict something from your data, each instance (e.g. row) of 
the data is marked with the actual observed value. If you data has no dependent variable, 
it is unlabeled data.</p><h4 id="who-labels-the-data">Who labels the data?</h4><p class="new">Some data can be labeled by using the end result of a process (e.g. the 
admission result of a student application, a loan given, etc) or set of experiments. 
Labeled data (especially image data) can also come from humans (e.g. 
students or a <a href="https://www.mturk.com/get-started" target="_blank">mechanical turk</a>).  In
almost all cases, getting large amounts of quality, trusted labeled data is
often an issue.</p><h1 class="section" id="section2">Supervised Machine Learning </h1><p class="new">For most <strong>supervised</strong> ML algorithms/techniques there is a notion of knowing
what the answer should be.  Hence, almost all supervised ML algorithms use
 labeled data. The goal of the ML algorithm is to determine how the 
 independent variables can be combined to predict the dependent variable or
 to figure out how to correctly predict the label based on seeing all the 
 other attributes of the data (or new engineered attributes).  </p><img alt="ClassVSRegTrans.png" class="inline mr-3 float-left" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/ClassVSRegTrans.png"/><p class="new">A few popular types of supervised ML are <strong>regression</strong> and <strong>classification </strong>. Both
attempt to predict the target/dependent variable; in regression it's a numeric 
value (i.e. continuous) and in classification it's a category (i.e. discrete). </p><p class="new">Algorithms like linear regression, logistic regression, k-nearest-neighbors (KNN), 
support vector machines and decision trees (to name a few) fall under
 the supervised ML umbrella. We will discuss several of these in future lessons.</p><h1 class="section" id="section3">Unsupervised Learning</h1><img alt="220px-K-means_convergence.gif" class="mr-3 float-left border" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/220px-K-means_convergence.gif"/><p class="new">For <strong>unsupervised</strong> ML algorithms, the goal is to discover patterns and 
structures in the data.  Since the data is <strong>NOT</strong> labeled, classified 
or assigned a target, there is no 'right' answer.  As you can imagine, one of
 the issues with unsupervised learning is determining the appropriate 
 performance metric. </p><p class="new">A few examples of these algorithms include <strong>clustering</strong> (pictured here), 
association rules, dimensionality reduction, expectation‚Äìmaximization (EM), outlier and
 anomaly detection (something outside the expected range of values).</p><h1 class="section" id="section4">Reinforcement Learning</h1><p class="new">One of the issues with both supervised and unsupervised learning is that the
performance of the model can never be <strong>BETTER</strong> than the data.  For
 example, if our goal was to build a model that is better at classifying images 
than the humans who labeled the data, we could never get there.</p><p class="new"><strong>Reinforcement</strong> learning refers to goal-oriented algorithms which learn how 
to attain a complex objective (goal) or how to maximize along a particular 
dimension over many steps. For example, if you wanted your model to learn 
how to play pong or chess and actually become better at the game, reinforcement 
learning would be part of it. </p><h2 id="pong-from-pixels">Pong From Pixels</h2><p class="new">Reinforcement learning uses the concepts of agents, environments, 
states, actions, feedback and rewards.  We are not going to go into
details (if any); however, a good paper/blog that shows how reinforcement 
learning is used to build a system to play <a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank">pong</a>.
Reinforcement learning is a very active field in ML.</p><h1 class="section" id="section5">Topics, Terms and Concepts</h1><img alt="iceberg.png" class="mr-3 my-3 float-left border iw300" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/iceberg.png"/><p class="new">As mentioned at the beginning, the world of machine learning is a giant 
mountain (or iceberg) to climb. There are semester based courses and careers that focus 
on very specific areas. Some will take you very deep into understanding the math and
 statistics, or the computational complexity behind the algorithm.</p><p class="new">It's a large and expanding field and our goal is to get you comfortable 
knowing the space and where to explore next.  Let's go over a few concepts that 
are part of the ML lexicon that will help smooth out our hike.</p><h2 id="neural-networks">Neural Networks</h2><img alt="NN.png" class="ml-3 my-3 float-right border iw400" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/NN.png"/><p class="new">As popular as neural networks (a.k.a. NN) are, you may have found it interesting that
it wasn't mentioned in the big three areas just discussed. </p><p class="new">In general, neural networks are a supervised ML algorithm where you are trying to build a
 function approximator to help classify or predict an outcome.  </p><p class="new"> You can imagine that if your data was generated by a process, you could
   replicate it if you knew the exact inputs into the process.  The ML model 
   built from a NN is an attempt to mimic the actual function (the 'oracle').  Formally, one can say that the
     training of a NN involves searching through the hypothesis space for a 
     candidate hypothesis. A hypothesis in this context is just a function 
     (that can be learned) that best maps its inputs (independent variables) 
     to outputs (dependent variables).</p><p class="new"> However, a NN can still be used with unlabeled data to find interesting relationships 
 and patterns. Many NLP algorithms are built on top of a NN using raw text. In this 
 situation a proxy is used to help measure how well the model fits the data. Word embeddings, 
 which we will learn about soon, are a good example of 'unsupervised learning' 
 that uses a NN to build the model.</p><p class="new"> With neural networks, we have another enormous mountain of vocabulary: convolution, 
 recurrent, long-short-term memory, activation, neurons, input layers, 
 hidden layers, feed-forward, back propagation, gradient descent and the list 
 goes on.  It's easy to feel overwhelmed -- especially at first. 
 But one by one some of these words and meanings will reveal themselves. Our 
 job is to wrap each with enough context (i.e. examples and code) so it
  becomes a manageable journey.</p><h2 id="deep-learning">Deep Learning</h2><p class="new">Deep learning is a class of machine learning algorithms that uses 
multiple layers to progressively extract higher level features from the 
raw input.  Much of deep learning is closely associated with deep neural
 networks.  A deep neural network is just a neural network with multiple
  layers. The image in the previous section is an example of a deep neural
   network -- it has more than one 'hidden' layer.</p><h2 id="semi-supervised-learning">Semi Supervised Learning</h2><p class="new">Another approach to ML is to combine a small amount of labeled data with the
 more readily available unlabeled data.  Labeled data is hard to get (i.e. 
 annotation is tedious and domain experts are needed).  While unlabeled data is
  easy to find.</p><h2 id="what-about-tfidf">What about TF‚Ä¢IDF?</h2><div class="font-sans container mt-1 mb-4 mt-0 mb-4"><div></div><div class="w-2/3 md:w-2/3"><div class="shadow-md"><div class="tab overflow-hidden border-t bg-green-200"><input class="absolute opacity-0" id="tab-multi-0" name="tabs" type="checkbox"/><label class="block p-3 leading-normal cursor-pointer" for="tab-multi-0"><span> Based on what you have seen and now read, <br/> do you think TF‚Ä¢IDF is a ML
algorithm? </span></label><div class="tab-content overflow-hidden border-l-2 bg-orange-300 border-indigo-500 leading-normal"><p class="p-3"><span>read on</span></p></div></div></div></div></div><br/><p class="new">TF‚Ä¢IDF is more of a statistical measure that indicates how relevant a word is 
to a document within a collection of documents. Also the TF‚Ä¢IDF algorithm 
doesn't need to train over a data set. However, the tf‚Ä¢idf metric can be used as both a 
input feature to a ML algorithm or as a way to evaluate the effectiveness of a model.
One interesting aspect of the sklearn's implementation is that it uses the
 same API for building, training (i.e. <strong><em>fit</em></strong>ting) a model.  As well as
  <strong><em>transform</em></strong>ing an input using the built model. </p><h2 id="parameters-and-hyper-parameters">Parameters and Hyper-Parameters</h2><p class="new">A machine learning model is essentially a mathematical formula with a number
 of parameters that needs to be 'learned' from the data. That is the essence of
  machine learning: fitting a model to the data. By training a model 
  with existing data, we are able to fit the model parameters.</p><p class="new">  However, most machine learning algorithms offer a plethora of options and
   parameters to use for building and training.  These parameters
    are chosen by the data scientist and are based on experience and model
     evaluation -- they are named the <em>hyper parameters</em> of the algorithm or
      the resulting model.</p><pre><code>Depending on the type of hyper-parameter, tuning can be done via using the 
validation dataset as well.
 </code></pre><h2 id="fitting-and-over-fitting">Fitting and Over fitting</h2><p class="new">As mentioned, <em>fitting</em> a model is the same as training a model.  However,
things can go wrong quickly.  We can both <em>under</em>fit a model (our model 
doesn't do a good job of prediction) or <em>over</em>fit a model.  In overfitting, 
our model fits the training data perfectly, but performs poorly on new (unseen) data.</p><p class="new"> We want to build a robust model such that we can give it new data (data 
 without a label) and predict one for it (accurately). Overfitting is where 
 the model uses invalid, misleading, wrong, impractical or noisy attributes 
 to perfectly fit the data.  </p><img alt="fitting.png" class="my-3 center border iw600" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/ml/mlprep/html/fitting.png"/><p class="new"> As an example, imagine a model whose output, the predicated eye color (dependent variable) 
 was determined from the name (independent variable) input rather than the genes of 
 the parents.  The 'result' might end up something like a lookup table:</p><pre><code>def predict_eyecolor(data):
   if data.name == 'bob':
      return 'blue'
   if data.name == 'jean':
      return 'green'
   if data.name == 'nancy':
      return 'brown'
   if data.name == 'mike':
      return 'blue'
   #.... 10000 more statements like this</code></pre><p class="new">That 'model', although might have a 100% predication rate, 
would fail (most likely) on new unforeseen data.</p><h2 id="batch-and-online-learning">Batch and Online Learning</h2><p class="new">You can also classify ML algorithms by whether or not they can learn
 incrementally from a stream of data or only with a fixed dataset.</p><p class="new">In batch learning (a.k.a offline learning) the algorithm trains using the
 available data.  If new data becomes available, you must retrain the system.</p><p class="new">In online learning (a.k.a out-of-core learning), you can train the model by
 using sequential data (think of a live stream of stock market prices or network intrusion data coming from a
  router).  These algorithms are also useful for handling massive datasets
   where the entire dataset cannot fit into memory.</p><p class="new"> </p><h2 id="whats-next">What's Next</h2><p class="new">Much of what we will learn is how and why these algorithms work and
when to apply them.  Of course, another level of mastery comes from 
having to implement the actual algorithms; however, we can approach 
that level of competence by learning the details of how each algorithm works. 
Having a solid handle on advanced mathematics is usually required to 
author your own algorithm (or to at least prove its complexity -- that is
 how it uses resources and behaves as its input data grows). You can
  still be an expert in ML and data science without authoring your own
   algorithms.</p><h1 class="section" id="section6">Lesson Assignment</h1><p class="new">This lesson lays the foundation of trying to build a map to organize the
 world of machine learning. If you find any of this perplexing, please re-read the lesson and post 
questions on piazza using the lesson tag: <strong>mlprep</strong>.</p><p class="new">A good idea to help you learn these concepts is to go through the lesson and
 create your own set of notes.  We used many different words to cover the 
 same concepts and topics -- it can be confusing.</p><p class="new"> You can breathe easily for this one. There is nothing to code or build.<br/> However, the content in this lesson is rich for quizzes. </p><p class="new"> <strong>Here are the requirements to get credit</strong>:</p><ol start="1"><li>You still need to download and submit it to gradescope to confirm that you 
did indeed read (and understood) the lesson.</li><li><p class="new">Post a response to either (or both) of the ML threads on Piazza that ask for
your input: </p><ul><li>What do you hope to learn about machine learning (can be a specific technique or a general category)</li><li>What do you find confusing about machine learning (can be a concept, topic, a word)</li></ul><p class="new">Note that we <em>may</em> not have enough time to address either of those wishes. But 
it will be good to know and we can provide you with additional resources as well.</p><h1>Submit</h1><p>You can download your notebook (via <code>ide.tester</code>) and upload that file to Gradescope (find lesson with tag <strong>mlprep</strong>).</p><div></div><div class="lesson-footer flex bg-gray-200 justify-center"><div class="lesson-footer-card displaycard bg-blue-200 border-t border-gray-400 max-w-2xl rounded overflow-hidden shadow-lg"><div class="px-6 py-4"><div class="title-text text-center font-bold text-xl">Machine Learning</div><p class="text-center text-gray-800 text-xl">Prepping for ML</p><div class="text-center mt-6 text-xl"><i aria-hidden="true" class="fas fa-tags"></i> any questions on Piazza with <span class="font-bold">mlprep</span></div><div class="text-gray-700 text-base">¬†</div><div></div><div></div><div class="flex mt-4 border-t border-solid border-gray-500 justify-around bg-gray-200"><div class="text-gray-700 text-center px-4 m-2 text-sm">D.M. &amp; the üêç</div><div class="text-gray-700 text-center px-4 m-2 text-sm"><strong>Version:</strong> <!-- -->SP21</div></div><div class="text-gray-700 mt-2 text-center text-sm font-bold">All Rights Reserved Michael Haberman</div><div class="text-gray-700 text-center text-sm">Do not distribute this notebook</div></div></div></div><div>¬†</div><div class="ide code-starter clearfix"><pre><code># print(ide.tester.test_notebook()) 
# print(ide.tester.test_notebook(verbose=True)) 

# once you are ready -- run this 
# ide.tester.download_solution() 
</code></pre></div></li></ol></div></div></body></html>