<!DOCTYPE html><html lang='en'><head><title>KNN</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}blockquote,h1,h2,h3,h4,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border-t{border-top-width:1px}.inline-block{display:inline-block}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-right{float:right}.float-left{float:left}.clearfix:after{content:"";display:table;clear:both}.clear-both{clear:both}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-none{line-height:1}.m-2{margin:.5rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.ml-3{margin-left:.75rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-full{width:100%}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.main-content{max-width:900px}.lesson{padding-left:15px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.main-content,html{font-family:Arial,Georgia,Verdana,"Times New Roman"!important}.lesson-footer-card,.lesson-overview-card{font-family:"Times New Roman"!important}blockquote em:first-child{font-family:Times!important;font-size:1.35em;margin-right:10px}blockquote em:first-child:after{content:":"}.lesson-footer{margin-top:50px;margin-top:20px}li>p{display:inline!important}.lesson ol{list-style-type:decimal;list-style-position:inside;margin-left:1em}.lesson ul{list-style-position:inside;list-style-type:none;margin-left:1em}.lesson ul li{padding-left:1em;padding-right:5px}.lesson ul li::before{content:"•";padding-right:5px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em}p.new+p{padding-top:.5em}h1,h2,h3,h4{font-weight:700;margin-top:.25em!important;margin-bottom:.05em!important;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{font-size:2em!important;clear:both;color:#000!important}div+h1,h2{margin-top:0!important}h2{margin-top:.5em!important;font-size:1.5em!important;clear:both;color:#8b0000!important}h3{font-size:1.25em!important;clear:both;color:#006400!important}h4{font-size:1em!important;clear:both;color:#00008b!important}ul{margin-bottom:30px}p.new a{text-decoration:underline}.lesson a{text-decoration:underline;color:#00f}.title-text{font-size:2rem}blockquote{font-size:1em;background:#f9f9f9;border-left:10px solid #ccc;margin:.5em 10px;padding:.5em 10px;border-left-color:#ffcd69;border-right-color:#f6ba59;quotes:"\201C""\201D""\2018""\2019"}blockquote:before{color:#ccc;content:open-quote;font-size:4em;line-height:.1em;margin-right:.25em;vertical-align:-.4em}blockquote:after{color:#ccc;content:no-close-quote}blockquote p{display:inline}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}img.formula-block{margin-left:auto;margin-right:auto;margin-top:.25rem;margin-bottom:.75rem}img.formula-inline{margin-top:.25rem;margin-bottom:.25rem}img.center{-o-object-position:center;object-position:center;margin-left:auto;margin-right:auto}img.border2{border:1px solid #94add4;margin-top:.5rem;margin-bottom:.75rem}img.iw400{height:auto;width:auto;max-width:400px}img.iw500{height:auto;width:auto;max-width:500px}img.iw300{height:auto;width:auto;max-width:300px}img.iw200{height:auto;width:auto;max-width:200px}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:840px;max-width:840px;overflow:scroll;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}</style>
<script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script>
<script>
    let stateCheck = setInterval(function(){
      if (document.readyState === 'complete') {
        clearInterval(stateCheck);
        let s1 = document.getElementById('start');
        // console.log('doc is ready', s1);
        if (s1) {
           s1.setAttribute('tabindex', '-1');
           s1.focus(); 
           s1.scrollIntoView({behavior: 'smooth'}); 
           setTimeout(function(){s1.blur()}, 500);
           // console.log('focus set');
        }
      }
    }, 200);
    </script>
</head><body class="lesson"><div class="main-content lesson bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<div id="start" class="section">&nbsp;</div><h1 class="section" id="section4">Managing Error</h1><p class="new">As mentioned in the evaluation section, managing the error of a model is a
 significant part of ML.</p><p class="new">The error of a model is made up <em>irreducible</em> and <em>reducible</em> parts:</p><img alt="math?math=%5CLarge%20Error%3D%5Ctext%7Birreducible%7D%20%2B%20%5Ctext%7Breducible%7D" class=" formula-block" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20Error%3D%5Ctext%7Birreducible%7D%20%2B%20%5Ctext%7Breducible%7D"/><ul><li><strong><em>irreducible error</em></strong> cannot be reduced.  The error may be coming from
something the model is not able to capture (unknown variables) or from
something adding noise to the data (inaccurate measurements, etc).</li><li><strong><em>reducible error</em></strong> is made up of <strong><em>bias</em></strong> and <strong><em>variance</em></strong>.</li></ul><img alt="math?math=%5CLarge%20Error%3Dnoise%5E2%20%2B%20%7Bbias%5E2%7D%20%2B%20%7Bvariance%7D" class=" formula-block" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20Error%3Dnoise%5E2%20%2B%20%7Bbias%5E2%7D%20%2B%20%7Bvariance%7D"/><ul><li>noise (unavoidable error)</li><li>bias (incorrect assumptions)</li><li>variance (variability of training samples)</li></ul><h2 id="bias-">Bias </h2><p class="new">The bias error is simply the difference between the predicated value and the
 actual value. The word bias within the context of describing the error of a model refers to
 the accuracy or quality of the predictions:</p><ul><li><strong>low</strong> bias: on average, the model accurately estimates the true parameter(s) from
training data</li><li><strong>high</strong> bias: the model makes inaccurate predictions. the average predicated values are far 
from the actual values (under-fitting via a simple model)</li></ul><h3 id="an-underfitted-model">An Underfitted Model</h3><img alt="underfit.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/underfit.png"/><p class="new">When a model is too simple it <em>under</em>fits the data. It does not take into 
account all the information in the data. </p><p class="new">For KNN, setting <code>k=n</code> would end up using the class with the highest number of 
instances in the training set.</p><h3 id="a-word-on-bias">A word on bias</h3><p class="new">The word bias contains negative connotations. We have all heard stories
 of how a ML algorithm made bad decisions because it was biased. Using an 
analogy in this context, bias can be thought as having a ‘bias’ towards people. If someone is 
highly biased, they are more likely to make wrong assumptions. However, if
 someone has no bias, they may have no concerns trying to pet a grizzly bear. </p><p class="new">Without any bias ML algorithms could not generalize to be useful 
(see <a href="http://dml.cs.byu.edu/~cgc/docs/mldm_tools/Reading/Need%20for%20Bias.pdf" target="_blank">mitchel</a>). 
Without a bias in linear regression (i.e. <img alt="math?math=%5Clarge%20y%3Dmx%2Bb" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20y%3Dmx%2Bb" style="display:inline-block"/>), all lines would go 
through the origin. It would be infeasible to build an accurate regression model 
for almost all datasets.</p><p class="new">The bigger problem with bias in ML is when the training data doesn't
 accurately reflect the population for which the model will be used. The
 model in this case will be <em>biased</em> towards data most similar to the training data.</p><h2 id="variance">Variance</h2><p class="new">Variance describes the variability of the predictions for a given point among 
different instantiations of the training data with the model.</p><ul><li><strong>low</strong> variance implies the estimate does not change as much as the
training set varies</li><li><strong>high</strong> variance model performs well on the training data but not on the test or
validation data. It does not generalize well (overfitting via a complex model).</li></ul><h3 id="an-overfitted-model">An Overfitted Model</h3><img alt="kis1.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/kis1.png"/><p class="new">You can actually get your model to be 100% accurate by fitting to the entire
 dataset and setting <code>k=1</code>. In this case, the decision boundaries get tightly
 wrapped around each instance. This is classic case of overfitting the data. </p><p class="new">When a model overfits the data, it does not (usually) generalize well for new
 predictions. There are strategies in addition to the ones shown here on
 preventing overfitting (or building a well generalized model). </p><h2 id="fixing">Fixing</h2><p class="new">Since a model will typically be unable to capture the full relationship of
 the data, it will be <em>bias</em>ed (regardless of parameters or with any amount
 of data). There is, unfortunately, a tradeoff between bias and variance: 
you can't minimize both.</p><img alt="b_v_tradeoff.png" class="center iw500 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/b_v_tradeoff.png"/><p class="new">Hence, A good model is where both bias and variance errors are balanced. You 
could (and should) verify this by looking at the score metrics for both the 
training and testing sets for different values of <code>K</code>.</p><pre><code>print('train', knn.score(X_train, y_train))
print('test', knn.score(X_test, y_test))</code></pre><ul><li><p class="new">High Bias — Low Variance (underfitting):</p><ul><li>The predictions will be similar to one another but on average, they are inaccurate.</li></ul></li><li><p class="new">Low Bias — High Variance (overfitting):</p><ul><li>Models are somewhat accurate but inconsistent on averages. A small change in 
the data can cause a large error.</li></ul></li></ul><p class="new">The following attempts to summarize the bias-variance landscape:  Note on the 
diagonal 'dimension' models move from simple under-fitting to complex over-fitting.</p><img alt="bias_variance.png" class="center iw400 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/bias_variance.png"/><p class="new">In some cases we can use techniques to make sure we don't overfit or underfit
 a model -- but it is always a balancing act.</p><h2 id="knn-inaccuracies">KNN inaccuracies:</h2><p class="new">We want our models to have low bias and low variance. The are accurate and consistent 
on averages. As mentioned, this is not always possible and there is usually a
 tradeoff. We can see the bias/variance tradeoff with KNN.</p><p class="new">When k is large(<code>k=n</code>) there is high bias. The model is not flexible and is
 overly simple (ignores training) and underfits the data.</p><p class="new">When k is small (<code>k=1</code>) there is high variance (sensitive to sample randomness), 
and it does not generalize well. It has low bias and the model overfits the data.</p><p class="new">So as you increase <code>k</code>, the bias increases, but the variance decreases (training errors 
go up; test errors go down). </p><h3 id="k-again"><em>K</em> again</h3><p class="new">It is wise to work with different <em>K</em> values.  Each model's error
 can be plotted against a set of hyper-parameters to determine a valid set.</p></div></div></body></html>