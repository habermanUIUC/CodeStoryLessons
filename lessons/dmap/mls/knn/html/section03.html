<!DOCTYPE html><html lang='en'><head><title>KNN</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}blockquote,h1,h2,h3,h4,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border-t{border-top-width:1px}.inline-block{display:inline-block}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-right{float:right}.float-left{float:left}.clearfix:after{content:"";display:table;clear:both}.clear-both{clear:both}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-none{line-height:1}.m-2{margin:.5rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.ml-3{margin-left:.75rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-full{width:100%}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.main-content{max-width:900px}.lesson{padding-left:15px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.main-content,html{font-family:Arial,Georgia,Verdana,"Times New Roman"!important}.lesson-footer-card,.lesson-overview-card{font-family:"Times New Roman"!important}blockquote em:first-child{font-family:Times!important;font-size:1.35em;margin-right:10px}blockquote em:first-child:after{content:":"}.lesson-footer{margin-top:50px;margin-top:20px}li>p{display:inline!important}.lesson ol{list-style-type:decimal;list-style-position:inside;margin-left:1em}.lesson ul{list-style-position:inside;list-style-type:none;margin-left:1em}.lesson ul li{padding-left:1em;padding-right:5px}.lesson ul li::before{content:"â€¢";padding-right:5px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em}p.new+p{padding-top:.5em}h1,h2,h3,h4{font-weight:700;margin-top:.25em!important;margin-bottom:.05em!important;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{font-size:2em!important;clear:both;color:#000!important}div+h1,h2{margin-top:0!important}h2{margin-top:.5em!important;font-size:1.5em!important;clear:both;color:#8b0000!important}h3{font-size:1.25em!important;clear:both;color:#006400!important}h4{font-size:1em!important;clear:both;color:#00008b!important}ul{margin-bottom:30px}p.new a{text-decoration:underline}.lesson a{text-decoration:underline;color:#00f}.title-text{font-size:2rem}blockquote{font-size:1em;background:#f9f9f9;border-left:10px solid #ccc;margin:.5em 10px;padding:.5em 10px;border-left-color:#ffcd69;border-right-color:#f6ba59;quotes:"\201C""\201D""\2018""\2019"}blockquote:before{color:#ccc;content:open-quote;font-size:4em;line-height:.1em;margin-right:.25em;vertical-align:-.4em}blockquote:after{color:#ccc;content:no-close-quote}blockquote p{display:inline}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}img.formula-block{margin-left:auto;margin-right:auto;margin-top:.25rem;margin-bottom:.75rem}img.formula-inline{margin-top:.25rem;margin-bottom:.25rem}img.center{-o-object-position:center;object-position:center;margin-left:auto;margin-right:auto}img.border2{border:1px solid #94add4;margin-top:.5rem;margin-bottom:.75rem}img.iw400{height:auto;width:auto;max-width:400px}img.iw500{height:auto;width:auto;max-width:500px}img.iw300{height:auto;width:auto;max-width:300px}img.iw200{height:auto;width:auto;max-width:200px}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:840px;max-width:840px;overflow:scroll;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}</style>
<script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script>
<script>
    let stateCheck = setInterval(function(){
      if (document.readyState === 'complete') {
        clearInterval(stateCheck);
        let s1 = document.getElementById('start');
        // console.log('doc is ready', s1);
        if (s1) {
           s1.setAttribute('tabindex', '-1');
           s1.focus(); 
           s1.scrollIntoView({behavior: 'smooth'}); 
           setTimeout(function(){s1.blur()}, 500);
           // console.log('focus set');
        }
      }
    }, 200);
    </script>
</head><body class="lesson"><div class="main-content lesson bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<div id="start" class="section">&nbsp;</div><p class="new">Clearly, the third car (ðŸš˜) is the closet to the test car. However, this story
 will be continued (ðŸš™ â“¶).</p><h3 id="birds-of-a--">Birds of a ðŸª¶ </h3><p class="new">K-Nearest Neighbors assumes that similar items will be close together (in
 high dimensional space). So those items who have the same attributes in
  common (or very close to each other), will be of the same class -- 
"Birds of a feather, flock together" and "Show me your friends, and I'll tell
 you who you are" are two common phrases spoken by KNN.</p><h2 id="a-k5-walk-through">A <em>K</em>5 Walk through</h2><img alt="voronoi1.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/voronoi1.png"/><p class="new">The following is a visual walk through of the KNN algorithm. 
We will use the dataset shown to the left on which to train.</p><ul><li>19 data points (8 red, 11 blue)</li><li><code>K = 5</code></li></ul><br class="clear-both"/><img alt="voronoi2.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/voronoi2.png"/><p class="new">We then ask the model to classify a new point </p><ul><li>new point is orange</li><li>the model needs to respond with either 'red' or 'blue':</li><li>the model selects the 5 nearest points to the new point</li></ul><br class="clear-both"/><img alt="withOrange.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/withOrange.png"/><p class="new">KNN (<code>k=5</code>) would then select the following points</p><ul><li>the points are selected based on L2 distance</li><li>the majority vote is 'blue'</li><li>the new point gets assigned the label 'blue'</li></ul><h2 id="decision-boundaries">Decision Boundaries</h2><img alt="db.png" class="float-right ml-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/db.png"/><p class="new">The goal of many ML algorithms is to generate a decision boundary (e.g. line, 
hyperplane, surface) that partitions the instances into different spaces (one 
for each class).</p><img alt="hyperplane.png" class="float-left mr-3 iw200 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/hyperplane.png"/><p class="new">If the decision surface is a hyperplane, then the classification problem is linear, 
and the classes are said to be <strong><em>linearly separable</em></strong>.</p><p class="new">If a point lies on a boundary, it's not clear which class it belongs to. The 
boundary itself is ambiguous as the output label of a classifier could be either class.</p><h3 id="k1-boundaries">K1 Boundaries</h3><img alt="voronoi3.png" class="float-left mr-3 iw400 border2" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/voronoi3.png"/><p class="new">Going back to our example, if <code>K=1</code>, each point would have its own decision
 boundary.  In fact a Voronoi diagram partitions a space in such a way that
  each region shares characteristics with KNN.</p><p class="new">In this example, each point defines a region such that if another point fell into 
its region, it would be the closest point to the new point. Each data point 
has a region for which it will vote for itself. </p><p class="new">KNN creates a decision boundary for classification.  In fact it can create 
very complicated, precise decision boundaries and is one of the reasons why 
over-fitting can be an issue.  </p><h2 id="special-k">Special K</h2><img alt="specialK.png" class="float-right ml-3 iw200" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/knn/html/specialK.png"/><p class="new">You maybe now be asking, "so how to pick the right K?".  Different <em>K</em> values
 will result in different decision boundaries. Too small of a <em>K</em> will result
 in a 'memorized' overfit model.  Too big, the model becomes simplistic.</p><p class="new">The <em>K</em> for this algorithm is a <strong><em>hyper-parameter</em></strong> -- a parameter that is not
 learned by the algorithm.  Hyper-parameters are selected through experience, 
 rules-of-thumb (best practices), research, and experimentation.</p><p class="new">When a model has multiple hyper-parameters, it can result in many different
 configurations in order to find an optimal configuration.</p><h3 id="start-with-sqrt">start with <code>sqrt</code></h3><p class="new">A good starting point is setting K to the square root of the number
 of instances in the data: <img alt="math?math=%5Clarge%20K%3Dint(%5Csqrt%7Bn%7D)" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20K%3Dint(%5Csqrt%7Bn%7D)" style="display:inline-block"/></p><h3 id="make-it-odd">make it odd</h3><p class="new">However if K is even, you will decrease it by one.  Since voting is done by
 majority rules; an odd K will relieve you from breaking ties.</p><h3 id="multiple-classes">multiple classes</h3><p class="new">Another adjustment is to make sure K isn't equal to the number of classes
 you have. In a multi-class situation, you can still end up with ties. For 
 example, if you have 3 classes and <code>K=3</code> and the closest neighbors are:</p><ol start="1"><li>red</li><li>green</li><li>blue</li></ol><p class="new">Who would win?
So K must not be a multiple of the number of classes in your labels. </p><h3 id="finding-k">finding K</h3><p class="new">Once we understand how to evaluate the KNN results, you can use a metric and
 just iterate over different values of K, selecting the one that gives you
  the best performance. If this is computationally infeasible, you can
 experiment with just a few different <code>K</code>'s or use sampling to build a
 smaller training set.</p></div></div></body></html>