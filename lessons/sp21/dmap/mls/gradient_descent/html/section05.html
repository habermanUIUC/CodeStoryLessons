<!DOCTYPE html><html lang='en'><head><title>Gradient Descent</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,h3,h4,p,pre{margin:0}ul{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border{border-width:1px}.border-t{border-top-width:1px}.inline-block{display:inline-block}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-left{float:left}.clearfix:after{content:"";display:table;clear:both}.clear-both{clear:both}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-none{line-height:1}.m-2{margin:.5rem}.m-4{margin:1rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.mt-4{margin-top:1rem}.mb-4{margin-bottom:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.text-red-700{--text-opacity:1;color:#c53030;color:rgba(197,48,48,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-full{width:100%}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.main-content{max-width:900px}.lesson{padding-left:15px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.main-content,html{font-family:Arial,Georgia,Verdana,"Times New Roman"!important}.lesson-footer-card,.lesson-overview-card{font-family:"Times New Roman"!important}.lesson-footer{margin-top:50px;margin-top:20px}.lesson ul{list-style-position:inside;list-style-type:none;margin-left:1em}.lesson ul li{padding-left:1em;padding-right:5px}.lesson ul li::before{content:"•";padding-right:5px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em}p.new+p{padding-top:.5em}h1,h2,h3,h4{font-weight:700;margin-top:.25em!important;margin-bottom:.05em!important;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{font-size:2em!important;clear:both;color:#000!important}div+h1,h2{margin-top:0!important}h2{margin-top:.5em!important;font-size:1.5em!important;clear:both;color:#8b0000!important}h3{font-size:1.25em!important;clear:both;color:#006400!important}h4{font-size:1em!important;clear:both;color:#00008b!important}ul{margin-bottom:30px}.title-text{font-size:2rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}img.formula-block{margin-left:auto;margin-right:auto;margin-top:.25rem;margin-bottom:.75rem}img.formula-inline{margin-top:.25rem;margin-bottom:.25rem}img.center{-o-object-position:center;object-position:center;margin-left:auto;margin-right:auto}img.border{border:1px solid #021a40;margin-top:.5rem;margin-bottom:.75rem}img.iw600{height:auto;width:auto;max-width:600px}img.iw400{height:auto;width:auto;max-width:400px}img.iw200{height:auto;width:auto;max-width:200px}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:840px;max-width:840px;overflow:scroll;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}</style>
<script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script>
<script>
    let stateCheck = setInterval(function(){
      if (document.readyState === 'complete') {
        clearInterval(stateCheck);
        let s1 = document.getElementById('start');
        // console.log('doc is ready', s1);
        if (s1) {
           s1.setAttribute('tabindex', '-1');
           s1.focus(); 
           s1.scrollIntoView({behavior: 'smooth'}); 
           setTimeout(function(){s1.blur()}, 500);
           // console.log('focus set');
        }
      }
    }, 200);
    </script>
</head><body class="lesson"><div class="main-content lesson bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<div id="start" class="section">&nbsp;</div><p class="new">The function <code>calculate_mse</code> has two degrees of freedom (<code>w0</code> and <code>w1</code>). Our initial
 plots from the previous lesson used just one of those weights. </p><p class="new">Here's what the graph looks like when you plot MSE vs <code>w0</code> and <code>w1</code>. That is we
 are plotting for all combinations of <code>w0</code> and <code>w1</code> (same graph, two different perspectives):</p><img alt="3dMSE1.png" class="float-left m-4 iw400" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/3dMSE1.png"/><img alt="3dMSE2.png" class="iw400" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/3dMSE2.png"/><br class="clear-both"/><p class="new">If you imagine looking straight at the <code>w0</code> axis, you would 'see' your 2D graph 
previously created.</p><h2 id="3d-gd">3D GD</h2><p class="new">Now rather than having a 'simple' graph to navigate, gradient descent will 
pick a random point on that mesh.  But now it has to consider the slopes 
for <code>w0</code> and <code>w1</code>. It can't make a decision in terms of which way is towards 
the minimum without taking into account both derivatives (slopes). </p><p class="new">Since the loss function for a line has two weights (or a weight for each independent 
variable and an additional one) you need to find the derivative for both. In 
this case, it's called finding <em>partial</em> derivatives.  </p><p class="new">A partial derivative is a derivative found for each weight while assuming the other
 weights are just constants. In mathematical notation, for a function <code>f</code> (the MSE
 loss function), we say:</p><h4 id="the-partial-derivative-of-f-with-respect-to-w-is-formula-classnamemy-1-inlinetrue-sizelarge-jaxfrac-partial-fpartial-w0-">The partial derivative of <code>f</code> with respect to <code>w₀</code> is <img alt="math?math=%5Clarge%20%5Cfrac%20%7B%5Cpartial%20f%7D%7B%5Cpartial%20w_0%7D" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%20%7B%5Cpartial%20f%7D%7B%5Cpartial%20w_0%7D" style="display:inline-block"/></h4><h4 id="the-partial-derivative-of-f-with-respect-to-w-is-formula-classnamemy-1-inlinetrue-sizelarge-jaxfrac-partial-fpartial-w1-">The partial derivative of <code>f</code> with respect to <code>w₁</code> is <img alt="math?math=%5Clarge%20%5Cfrac%20%7B%5Cpartial%20f%7D%7B%5Cpartial%20w_1%7D" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%20%7B%5Cpartial%20f%7D%7B%5Cpartial%20w_1%7D" style="display:inline-block"/></h4><br/><p class="new">Many times the letter <code>d</code> will be used instead of <code>ϑ</code> (theta <code>θ</code>).</p><br/><p class="new">It is at this point, we ask our calculus friends to find those derivatives for us. 
 When using gradient descent you <strong>don't have to know the mechanics of how to find derivatives</strong>, 
 the libraries you will use have that figured out.  When we get to
  neural networks the partial derivatives are a big part of back-propagation
 and can get a bit messy (again, we are getting ahead of ourselves).</p><h2 id="partials-derivatives-for-gd-linear-regression">Partials Derivatives for GD (linear regression)</h2><p class="new">As mentioned in the linear regression lesson, sometimes you will see MSE 
expressed as a loss function using the letter 'J' (a homage to the Jacobian matrix)</p><ul><li><img alt="math?math=%5Clarge%20MSE%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)%5E2" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20MSE%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)%5E2" style="display:inline-block"/></li><li><img alt="math?math=%5Clarge%20J(w_0%2C%20w_1)%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)%5E2" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20J(w_0%2C%20w_1)%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)%5E2" style="display:inline-block"/></li></ul><p class="new">Here are the two partial derivatives for the loss function MSE (already
 solved for us):</p><ul><li><img alt="math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_0%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_0%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)" style="display:inline-block"/></li><li><img alt="math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_1%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%20x_i%20(y_i%20-%20(w_0%20%2B%20w_1x_i))" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_1%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%20x_i%20(y_i%20-%20(w_0%20%2B%20w_1x_i))" style="display:inline-block"/></li></ul><p class="new">Depending on who's in the mathroom, you may also see the following:</p><ul><li><img alt="math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_0%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_0%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0%20%2B%20w_1x_i)%20)" style="display:inline-block"/></li><li><img alt="math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_1%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum%20x_i%20(y_i%20-%20(w_0%20%2B%20w_1x_i))" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_1%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum%20x_i%20(y_i%20-%20(w_0%20%2B%20w_1x_i))" style="display:inline-block"/></li></ul><h4 id="extension-for-linear-algebra">Extension for Linear Algebra</h4><p class="new">Another simplification that you may see (we won't be using this version) is
 to add an <img alt="math?math=%5Clarge%20x_0" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20x_0" style="display:inline-block"/> variable and set it to 1 for all instances (essentially 
adding another column/attribute).  When GD is implemented using linear
 algebra, this is usually the way it's implemented.</p><ul><li><img alt="math?math=%5Clarge%20MSE%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0x_0%20%2B%20w_1x_i)%20)%5E2" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20MSE%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum(%20y_i%20-%20(w_0x_0%20%2B%20w_1x_i)%20)%5E2" style="display:inline-block"/></li><li><img alt="math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_i%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum%20x_i%20(y_i%20-%20(w_0x_0%20%2B%20w_1x_i))" class="my-1 formula-inline" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20%5Cfrac%7Bd%7D%7Bdw_i%7D%20%3D%20%5Cfrac%7B1%7D%7B2n%7D%5Csum%20x_i%20(y_i%20-%20(w_0x_0%20%2B%20w_1x_i))" style="display:inline-block"/></li></ul><h2 id="use-the-gradient">Use the <strong>Gradient</strong></h2><p class="new">The <em>gradient</em> in gradient descent is the set of functions (ultimately expressed
 inside of a matrix) that represent the slopes of the cost/loss function. The gradient 
 is the set of partial derivatives (slopes).</p><p class="new">To repeat, the gradient is for the <strong>cost</strong> function.</p><h3 id="finding-your-way-home-with-blind-faith">Finding Your Way Home (with Blind Faith)</h3><img alt="gradient.png" class="float-left mr-3" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/gradient.png"/><p class="new">If you think of the loss function (i.e. the objective function) as a landscape, 
then to find your way home (where the loss is at its lowest point), you should
 proceed as follows: </p><ul><li>start at some random place on the landscape</li><li>always move on the best path to a low ground (local minimum).</li><li>the best path is always the fastest path downward (consulting all directions).</li><li>the gradient is your guide.</li></ul><p class="new">Here's our updated algorithm (Version 2.0) :</p><pre><code>     w0, w1 # pick random values to begin with
     while not finished:

         mse = calculate_mse(xv, yv, [w0, w1])
         if near threshold:
             done  

         # calculate partial derivatives (errors)
         for i in range(n):
            w0_sum += (yv[i] - (w1*xv[i] + w0))
            w1_sum += (yv[i] - (w1*xv[i] + w0)) * xv[i] 
         d_w0 = (-2/n) * w0_sum
         d_w1 = (-2/n) * w1_sum

         # update the weights (step size)
         w0 = w0 - d_w0
         w1 = w1 - d_w1</code></pre><p class="new">The <strong>important part</strong> is seeing how we update the weights (the last 2 lines). </p><p class="new">If the new slope is negative</p><ul><li>we increase our guess a little bit (we subtract a negative)</li></ul><p class="new">If the new slope is positive</p><ul><li>we need to decrease our guess a little bit</li></ul><p class="new">The following shows the path taken by gradient descent for our data (with
 both <code>w0</code> and <code>w1</code> purposely initialized with bad values.</p><img alt="path1.png" class="float-left mr-3 iw400" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/path1.png"/><img alt="path2.png" class="float-left mr-3 iw400" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/path2.png"/><br class="clear-both"/><p class="new">You can see that the slope of <code>w1</code> has a bigger impact in the direction to
 pursue at first, and then the slope of <code>w0</code> has a bigger influence.</p><h2 id="the-learning-rate">The 'Learning' rate</h2><p class="new">The one area for concern is our update rule (how the weights get updated). 
Right now, if the slope, for example, was -18.00, our next step would be +18
 steps in the x direction. That might jump <strong>right over the true minimum</strong>.</p><img alt="learning.png" class="center iw600" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/learning.png"/><p class="new">If you take too small of as step, converging on the local minimal can take a very 
long time. If you take too big of a step, you can jump past your goal:</p><p class="new">The solution is to dampen the effect by multiplying the slope (i.e. the next step) 
by a small amount -- called the learning rate. The result is called the step size:</p><img alt="math?math=%5CLarge%20step%20%3D%20learning%5C%2C%20rate%20%5Ctimes%20slope" class=" formula-block" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20step%20%3D%20learning%5C%2C%20rate%20%5Ctimes%20slope"/><p class="new">The learning rate (α) gives us some additional control over how large of 
steps we make. </p><img alt="learningRates.png" class="center mb-4" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/mls/gradient_descent/html/learningRates.png"/><p class="new">With a very low learning rate, we can confidently move in the direction of 
the negative gradient at the cost of more calculations/steps. </p><p class="new">With a large learning rate, we can cover more ground each step, 
but we risk overshooting the lowest point since the slope of the hill is 
constantly changing. </p><p class="new">The most commonly used rates are: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3. </p><h2 id="normalizing-input">Normalizing input</h2><p class="new">A common technique to ensure GD converges quickly is to ensure the data is
 normalized to a 0-1 scale. If one attribute is orders of magnitude larger than 
the others, GD can result in numerical errors (overflow, instability). If you
 are unable to normalize the data and the attributes have different scales, 
you usually have to insist on a very small learning rate.</p></div></div></body></html>