{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data, Machines and the üêç \n",
    "<img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/dmap/data/normalization/html/section00.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Notebook Preparation for Lesson 1‚Ä¢2‚Ä¢3\n",
    "Each lesson will start with a similar template (given in the course schedule):  \n",
    "1. **save** to your google drive (copy to drive)<br/><img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/assets/images/colab/copy-to-drive.png\"/>\n",
    "2. **update** the NET_ID to be your netID (no need to include @illinois.edu)\n",
    "3. **run** the next cell to install the IDE. <img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/assets/images/colab/play-button.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "LESSON_ID = 'dmap:data:normalization'   # keep this as is\n",
    "NET_ID    = 'CHANGE_ME' # CHANGE_ME to your netID (keep the quotes)\n",
    "\n",
    "def install_ide(net_id, lesson_id):\n",
    "  import sys\n",
    "  if 'codestories' not in sys.modules:\n",
    "      print('installing modules')\n",
    "      !pip install git+https://mehaberman@bitbucket.org/mehaberman/codestories.git --upgrade &> install.log\n",
    "  \n",
    "  from codestories.cs.CodeStories import CodeStory\n",
    "  return CodeStory(net_id, lesson_id)\n",
    "\n",
    "ide = install_ide(NET_ID, LESSON_ID)\n",
    "print(ide.welcome())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Data Normalization (part 1)\n",
    "(hit ‚ñ∂ to read the first part of the lessonÔ∏è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Mssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LessonUtil as Util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "def build_titanic():\n",
    "  df = pd.read_csv(Util.path_for_data('titanic.csv'))\n",
    "  print('total rows', len(df))\n",
    "  \n",
    "  # add an extra passenger\n",
    "  extra = {'name': 'Jack Dawson', 'age': 28, 'id': len(df)+1, 'gender': 'male'}\n",
    "  df = df.append(extra, ignore_index=True)\n",
    "  \n",
    "  # add an extra field for using a custom transformer\n",
    "  df['sid'] = df['age'].apply(lambda x: 'NA' if np.isnan(x) else \"{:.0f}\".format(1912-x)).astype('string')\n",
    "  df['sid'].replace('NA', np.nan, inplace=True)\n",
    "  \n",
    "  return df.copy()\n",
    "\n",
    "df = build_titanic()\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing(df):\n",
    "  print(df.isna().sum())\n",
    "\n",
    "show_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_missing_age(df, debug=True):\n",
    " \n",
    "  # mask to select the rows where age is empty\n",
    "  mask = df.age.isna()\n",
    "\n",
    "  # calculate the mean (the replacement value)\n",
    "  replace_value = df.age.mean()\n",
    "  \n",
    "  # fill those values with the value calculated\n",
    "  df['age_clean']= df[mask].age.fillna(replace_value)\n",
    "  if debug:\n",
    "    # print out the updates\n",
    "    cols = ['id', 'name', 'age', 'age_clean']\n",
    "    print(df[mask][cols].head())\n",
    "    \n",
    "# pass in a copy, so we keep the original\n",
    "process_missing_age(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_missing_age_skl(df, debug=True):\n",
    "  from sklearn.impute import SimpleImputer\n",
    "  import numpy as np\n",
    "\n",
    "  # np.nan is the how pandas marks missing values\n",
    "  # replace with the mean\n",
    "  imr = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\n",
    "\n",
    "  # Impute values\n",
    "  values = df.age.values.reshape(-1,1)  \n",
    "  out = imr.fit_transform(values)\n",
    "  \n",
    "  # now we assign those values to a new column\n",
    "  df['im_age'] = out\n",
    "\n",
    "  if debug:\n",
    "    cols = ['id', 'name', 'age', 'im_age']\n",
    "    mask = df.age.isna()\n",
    "    print(df[mask][cols].head())\n",
    "    print('Missing')\n",
    "    print(df.isna()[cols].sum())\n",
    "\n",
    "process_missing_age_skl(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_to_number(df, col_name, new_name, debug=True):\n",
    "\n",
    "  # map the categories to unique integers (starting at 0)\n",
    "  df[new_name] = df[col_name].astype(\"category\").cat.codes\n",
    "\n",
    "  if debug:\n",
    "    values = df[col_name].unique()\n",
    "    print('{:d} unique values for {:s}:'.format(len(values), col_name), values)\n",
    "    # show how many rows are in each group\n",
    "    print(df.groupby([col_name]).count()[new_name].reset_index())\n",
    "    print(df.groupby([col_name]).count()[new_name].sum())\n",
    "    \n",
    "  return df\n",
    "  \n",
    "# map gender to a 0/1 code\n",
    "cols = ['gender', 'g_code']\n",
    "df2 = category_to_number(df.copy(), *cols)  # putting * to good use\n",
    "print(df2[cols][0:10]) # first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map port of embarkation (C, Q, S) \n",
    "# C = Cherbourg, Q = Queenstown, S = Southampton,  B = ??\n",
    "cols = ['embarked', 'e_code']\n",
    "df = category_to_number(df.copy(), *cols)  \n",
    "print(df[cols][0:10]) # first 10 rows\n",
    "mask = df.embarked.isna()\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_class_attribute(df, debug=True):\n",
    "\n",
    "  # map 1st/2nd/3rd class as ordinal 1st < 2nd < 3rd + missing\n",
    "  # replace nan with the value 'unknown'\n",
    "  df['class'].fillna('unknown', inplace=True)\n",
    "  # assign the labels values\n",
    "  ord_map = {'3rd':3, '2nd':2, '1st':1, \n",
    "             'engineering crew':4, \n",
    "             'victualling crew':4, \n",
    "             'restaurant staff':4, \n",
    "             'deck crew':4, 'unknown':0}\n",
    "            \n",
    "  # apply the map to the 'class' attribute\n",
    "  df['o_class'] = df['class'].map(ord_map)\n",
    " \n",
    "  if debug:\n",
    "    print(df['class'].unique().tolist())\n",
    "    # show how many rows are in each group\n",
    "    print(df.groupby(['class']).count()['o_class'].reset_index())\n",
    "\n",
    "  return df\n",
    "\n",
    "df_class = map_class_attribute(df.copy())\n",
    "print(df_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_passenger_class_stats(df):\n",
    "  is_crew = df['o_class'].isin([4])\n",
    "\n",
    "  # any of these will work\n",
    "  is_pass = df['o_class'].isin([1,2,3])\n",
    "  is_pass = (df['o_class'] < 4 ) & (df['o_class'] > 0)\n",
    "  is_pass = ~is_crew  # will include the unknowns\n",
    "  \n",
    "  print('crew', len(df[is_crew]))\n",
    "  print('pass', len(df[is_pass]))\n",
    "\n",
    "# this assumes map_class_attribute is done\n",
    "print_passenger_class_stats(df_class.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_field(df, debug=True):\n",
    "  # Binary Fields\n",
    "  from sklearn.preprocessing import Binarizer\n",
    "  binarizer = Binarizer(threshold=3, copy=True)  # <= 3 asssing \n",
    "  column_values = binarizer.fit_transform(df.o_class.values.reshape(-1, 1))\n",
    "  \n",
    "  # flip the values (1 -> 0; 0 -> 1)\n",
    "  df['is_passenger'] = 1 - column_values  \n",
    "  if debug:\n",
    "    print(column_values)\n",
    "    print(df.head(5))\n",
    "\n",
    "print(create_binary_field(df_class.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "  import numpy as np\n",
    "  from sklearn.preprocessing import OneHotEncoder\n",
    "  \n",
    "  onehot = OneHotEncoder(dtype=np.int, sparse=True)\n",
    "\n",
    "  # fill in any missing values with 'UNK'\n",
    "  df['embarked'].fillna('UKN', inplace=True)\n",
    "  values = df['embarked'].values.reshape(-1, 1)\n",
    "  values = onehot.fit_transform(values).toarray() # it is sparse\n",
    "  labels = onehot.categories_\n",
    "\n",
    "  return pd.DataFrame(values, columns=labels)\n",
    "  \n",
    "df_hot = one_hot_encoding(df.copy())\n",
    "print(df_hot.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning data\n",
    "def bin_demo1(df):\n",
    "  # set up custom bins\n",
    "  bins =   [ 0,       3,      8,      16,           21,     35,      55,  200] \n",
    "  labels = ['infant','child','youth','young adult','adult','middle','senior']\n",
    "  age_bins = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "  df['age_cat'] = age_bins\n",
    "  print(df['id age age_cat'.split()].head(10))\n",
    "  return df\n",
    "\n",
    "df_bin = bin_demo1(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_demo2(df):\n",
    "  # uniform bins\n",
    "  from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "  # this must be done first\n",
    "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "  \n",
    "  binner = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy='uniform')\n",
    "  values = binner.fit_transform(df['age'].values.reshape(-1, 1))\n",
    "  df['age_cat2'] = values\n",
    "  print(df['id age age_cat age_cat2'.split()].head(10))\n",
    "\n",
    "bin_demo2(df_bin.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_demo3(df):\n",
    "  # one hot binning\n",
    "  from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "  bin_count = 4\n",
    "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "  binner = KBinsDiscretizer(n_bins=bin_count, encode='onehot-dense', strategy='uniform')\n",
    "  values = binner.fit_transform(df['age'].values.reshape(-1, 1))\n",
    "  labels = ['bin {:d}'.format(i) for i in range(1, bin_count+1)]\n",
    "\n",
    "  df2 = pd.DataFrame(values, columns=labels)\n",
    "  df2['age'] = df['age']\n",
    "  print(df2.head(10))\n",
    "\n",
    "bin_demo3(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fare_stats(df):\n",
    "  df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
    "\n",
    "  print(df['fare'].min())\n",
    "  min_fair = np.min(df['fare'])\n",
    "  max_fair = np.max(df['fare'])\n",
    "  print(min_fair, max_fair)\n",
    "  print(np.ptp(df['fare']))\n",
    "\n",
    "df = build_titanic()\n",
    "fare_stats(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_min_max_scaled_np(df):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def fare_min_max_scaled(df):\n",
    "  df['fare_scaled'] = minmax_scale(df['fare'])\n",
    "\n",
    "  # fit & transform way\n",
    "  scaler = MinMaxScaler()\n",
    "  s_values = scaler.fit_transform(df['fare'].values.reshape(-1,1))\n",
    "  df['fare_scaled2'] = s_values\n",
    "  print(df['fare fare_scaled fare_scaled2'.split()].head(10))\n",
    "\n",
    "fare_min_max_scaled(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fare_z_scaled(df):\n",
    "\n",
    "  # simple way\n",
    "  df['fare_z'] = scale(df['fare'])\n",
    "\n",
    "  # fit & transform way\n",
    "  scaler = StandardScaler()\n",
    "  s_values = scaler.fit_transform(df['fare'].values.reshape(-1,1))\n",
    "  df['fare_z2'] = s_values\n",
    "  print(df['fare fare_z fare_z2'.split()].head(10))\n",
    "\n",
    "fare_z_scaled(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_fare_outliers(df):\n",
    "  df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
    "  data = df['fare'].values.reshape(-1,1)\n",
    "\n",
    "  m = np.mean(data)\n",
    "  s = np.std(data)\n",
    "\n",
    "  # identify outliers\n",
    "  cut_off = s * 3.5 # pick any number of standard deviations (usually >= 2.0)\n",
    "  lower, upper = m - cut_off, m + cut_off\n",
    "  # identify outliers\n",
    "  outliers = [x for x in data if x < lower or x > upper]\n",
    "  print(\"{:d} outliers: min {:.2f} max {:.2f}\".format(len(outliers), np.min(outliers), np.max(outliers)))\n",
    "  \n",
    "  # remove outliers\n",
    "  # outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "\n",
    "find_fare_outliers(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sid(df):\n",
    "   # need to implement this function\n",
    "   # using the FunctionTransformer\n",
    "   pass\n",
    "   \n",
    "def demo_custom_cleaning(df):\n",
    "  try:\n",
    "    # this will not work\n",
    "    df['sid'] = df['sid'] - 1912 \n",
    "  except Exception as e:\n",
    "    print('invalid math')\n",
    "\n",
    "  # clean it so we can do math on it\n",
    "  df_c = clean_sid(df)\n",
    "\n",
    "  df_c['sid'] = 1912 - df_c['sid']\n",
    "  print(df_c.head())\n",
    "\n",
    "demo_custom_cleaning(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import LessonUtil as Util\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ide.tester.test_notebook()) \n",
    "# print(ide.tester.test_notebook(verbose=True)) \n",
    "\n",
    "# once you are ready -- run this \n",
    "# ide.tester.download_solution()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Normalization (part 1)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language": "python",
  "story": {
   "auth_token": "yCwuZ2VIgBEn2WzX2vXxAVTzMujqSHd_2URawanlmdI=",
   "authorship_tag": "AB",
   "chapters": 65,
   "name": "Data Normalization (part 1)",
   "parser": {},
   "root": "https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons",
   "tag": "dmap:data:normalization"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
