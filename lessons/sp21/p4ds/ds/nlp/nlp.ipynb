{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming w/üêç for Data Science \n",
    "<img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/p4ds/ds/nlp/html/section00.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Notebook Preparation for Lesson 1‚Ä¢2‚Ä¢3\n",
    "Each lesson will start with a similar template (given in the course schedule):  \n",
    "1. **save** to your google drive (copy to drive)<br/><img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/assets/images/colab/copy-to-drive.png\"/>\n",
    "2. **update** the NET_ID to be your netID (no need to include @illinois.edu)\n",
    "3. **run** the next cell to install the IDE. <img src=\"https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/assets/images/colab/play-button.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "LESSON_ID = 'p4ds:ds:nlp'   # keep this as is\n",
    "NET_ID    = 'CHANGE_ME' # CHANGE_ME to your netID (keep the quotes)\n",
    "\n",
    "def install_ide(net_id, lesson_id):\n",
    "  import sys\n",
    "  if 'codestories' not in sys.modules:\n",
    "      print('installing modules')\n",
    "      !pip install git+https://mehaberman@bitbucket.org/mehaberman/codestories.git --upgrade &> install.log\n",
    "  \n",
    "  from codestories.cs.CodeStories import CodeStory\n",
    "  return CodeStory(net_id, lesson_id)\n",
    "\n",
    "ide = install_ide(NET_ID, LESSON_ID)\n",
    "print(ide.welcome())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Natural Language Processing\n",
    "(hit ‚ñ∂ to read the first part of the lessonÔ∏è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def nltk_tokenize_demo(text):\n",
    "  for sentence in nltk.sent_tokenize(text):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    print(tokens)\n",
    "    \n",
    "demo = \"This is a simple sentence. Followed by another!\"\n",
    "nltk_tokenize_demo(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"We went to a clump of bushes, and Tom made everybody swear to keep the secret, and then showed them a hole in the hill, right in the thickest part of the bushes. \"\n",
    "nltk_ngram_demo(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def nltk_sentiment_demo():\n",
    "  \n",
    "  sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "  \n",
    "  # helper\n",
    "  def polarity_scores(doc):\n",
    "      return sentiment_analyzer.polarity_scores(doc)\n",
    "  doc1 = \"INFO 490 is so fun.\"\n",
    "  doc2 = \"INFO 490 is so awful.\"\n",
    "  doc3 = \"INFO 490 is so fun that I can't wait to take the follow on course!\"\n",
    "  doc4 = \"INFO 490 is so awful that I am glad there's not a follow on course!\"\n",
    "\n",
    "  print(polarity_scores(doc1)) # most positive\n",
    "  print(polarity_scores(doc2)) # most negative\n",
    "  print(polarity_scores(doc3)) # mostly positive, neutral\n",
    "  print(polarity_scores(doc4)) # mostly negative, a little positive too\n",
    "\n",
    "nltk_sentiment_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_stem_and_lemm_demo():\n",
    "\n",
    "  words = [\"game\",\"gaming\",\"gamed\",\"games\",\"gamer\",\"grows\",\"fairly\",\"nonsensical\"]\n",
    "\n",
    "  ps  = nltk.stem.PorterStemmer()\n",
    "  sno = nltk.stem.SnowballStemmer('english')\n",
    "  lan = nltk.stem.lancaster.LancasterStemmer()\n",
    " \n",
    "  for word in words:\n",
    "    base  = ps.stem(word)\n",
    "    sbase = sno.stem(word)\n",
    "    lbase = lan.stem(word)\n",
    "  \n",
    "    s = ''\n",
    "    if (sbase != base):\n",
    "      s += \"(or {})\".format(sbase)\n",
    "    if (lbase != base and lbase != sbase):\n",
    "      s += \"(or {})\".format(lbase)\n",
    "  \n",
    "    print(\"{:11s} stems to {:s} {}\".format(word, base, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_characters_nlp(text, topn):\n",
    "  # returns top n characters found in text\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ide.tester.test_notebook()) \n",
    "# print(ide.tester.test_notebook(verbose=True)) \n",
    "\n",
    "# once you are ready -- run this \n",
    "# ide.tester.download_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(29)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Natural Language Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language": "python",
  "story": {
   "auth_token": "ERrjkzCm-o-_3NidolGeqg==",
   "authorship_tag": "AB",
   "chapters": 30,
   "name": "Natural Language Processing",
   "parser": {},
   "root": "https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons",
   "tag": "p4ds:ds:nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
