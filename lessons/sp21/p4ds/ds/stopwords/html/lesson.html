<!DOCTYPE html><html lang='en'><head><title>🛑 Words</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}input{font-family:inherit;font-size:100%;line-height:1.15;margin:0}input{overflow:visible}[type=checkbox]{box-sizing:border-box;padding:0}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,p,pre{margin:0}ul{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}input:-ms-input-placeholder{color:#a0aec0}input::-ms-input-placeholder{color:#a0aec0}input::-moz-placeholder{color:#a0aec0}h1,h2{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}input{padding:0;line-height:inherit;color:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-orange-300{--bg-opacity:1;background-color:#fbd38d;background-color:rgba(251,211,141,var(--bg-opacity))}.bg-green-200{--bg-opacity:1;background-color:#c6f6d5;background-color:rgba(198,246,213,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.border-indigo-500{--border-opacity:1;border-color:#667eea;border-color:rgba(102,126,234,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border-l-2{border-left-width:2px}.border-t{border-top-width:1px}.cursor-pointer{cursor:pointer}.block{display:block}.inline-block{display:inline-block}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.clearfix:after{content:"";display:table;clear:both}.font-sans{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-none{line-height:1}.leading-normal{line-height:1.5}.m-2{margin:.5rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mb-3{margin-bottom:.75rem}.mt-4{margin-top:1rem}.mb-4{margin-bottom:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.opacity-0{opacity:0}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.p-3{padding:.75rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.absolute{position:absolute}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-2\/3{width:66.666667%}.w-full{width:100%}@media (min-width:768px){.md\:w-2\/3{width:66.666667%}}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.main-content{max-width:900px}.lesson{padding-left:15px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.main-content,html{font-family:Arial,Georgia,Verdana,"Times New Roman"!important}.lesson-footer-card,.lesson-overview-card{font-family:"Times New Roman"!important}.lesson-footer{margin-top:50px;margin-top:20px}.lesson ul{list-style-position:inside;list-style-type:none;margin-left:1em}.lesson ul li{padding-left:1em;padding-right:5px}.lesson ul li::before{content:"•";padding-right:5px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em}p.new+p{padding-top:.5em}h1,h2{font-weight:700;margin-top:.25em!important;margin-bottom:.05em!important;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{font-size:2em!important;clear:both;color:#000!important}div+h1,h2{margin-top:0!important}h2{margin-top:.5em!important;font-size:1.5em!important;clear:both;color:#8b0000!important}ul{margin-bottom:30px}p.new a{text-decoration:underline}.lesson a{text-decoration:underline;color:#00f}.title-text{font-size:2rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:840px;max-width:840px;overflow:scroll;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}.tab{font-size:1rem;border-color:#8c6728}.tab-content{max-height:0;max-width:100%;transition:max-height .35s}.tab input:checked~.tab-content{max-height:100vh}.tab input:checked+label{padding:1rem;border-left-width:2px;border-color:#6574cd;background-color:#f8fafc;color:#6574cd}.tab label::after{float:right;right:0;top:0;display:block;width:1em;height:1.5em;line-height:1.5;font-size:1rem;text-align:center;transition:all .35s}.tab input[type=checkbox]+label::after{content:"+";font-weight:700;border-width:1px;border-radius:9999px;border-color:#8c6728}.tab input[type=checkbox]:checked+label::after{transform:rotate(315deg);background-color:#6574cd;color:#f8fafc}</style>
<script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script>
<script>
    let stateCheck = setInterval(function(){
      if (document.readyState === 'complete') {
        clearInterval(stateCheck);
        let s1 = document.getElementById('start');
        // console.log('doc is ready', s1);
        if (s1) {
           s1.setAttribute('tabindex', '-1');
           s1.focus(); 
           s1.scrollIntoView({behavior: 'smooth'}); 
           setTimeout(function(){s1.blur()}, 500);
           // console.log('focus set');
        }
      }
    }, 200);
    </script>
</head><body class="lesson"><div class="main-content lesson bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<div id="start" class="section">&nbsp;</div><h1 class="overview"></h1><div class="lesson-overview bg-gray-200 flex justify-center"><div class="text-center px-4 py-2 m-2"><div class="lesson-overview-card displaycard bg-blue-200 max-w-sm rounded overflow-hidden shadow-lg"><div> </div><img alt="Text" class="object-contain h-64 w-full" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/p4ds/ds/stopwords/html/ds-sm.png"/><div class="px-6 py-4"><div class="title-text text-center leading-none font-bold text-xl">🛑 Words</div><p class="text-center mt-2 text-gray-800 text-xl">Getting rid of the useless</p><div class="text-gray-700 text-base"> </div><div class="text-center mb-3"><span class="inline-block bg-gray-300 rounded-full px-3 py-1 text-sm font-semibold text-gray-700 mr-2">#info490</span></div><div class="flex border-t border-solid border-gray-500 shadow-inner justify-around bg-blue-300"><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap">🐍  4 D.S.</span></div><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap"><strong>Version:</strong> <!-- -->SP21</span></div></div><div class="text-gray-700 mt-1 text-center text-tiny">All Rights Reserved</div></div></div></div><div class="text-center px-4 py-2 m-2 w-1/2"><div class="displaycard bg-gray-200 max-w-sm rounded overflow-hidden shadow-lg"><div class="px-6 py-4 text-left"><div class="text-center font-bold text-xl">🛑 Words<br/><div><span>prerequisites</span><div class="text-center text-xs mb-2">(start only after finishing)</div><p class="max-w-sm text-gray-800 text-sm">⦿ <strong>bootcamp</strong></p><p class="max-w-sm text-gray-800 text-sm">⦿ <strong>local I/O</strong></p><p class="max-w-sm text-gray-800 text-sm">⦿ <strong>array slicing</strong></p><p class="max-w-sm text-gray-800 text-sm">⦿ <strong>ngrams</strong></p></div></div></div><div class="px-6 py-4 text-left text-gray-800"><div class="text-center font-bold text-xl">Colab Notes</div><p class="max-w-sm text-sm">1. <strong>Copy</strong> this notebook <img alt="copy2drive.png" class="inline-block" src="https://raw.githubusercontent.com/habermanUIUC/CodeStoryLessons/main/lessons/p4ds/ds/stopwords/html/copy2drive.png"/></p><p class="max-w-sm text-sm">2. <strong>Update</strong> the <strong><code>NET_ID</code></strong> in the notebook</p><p class="max-w-sm text-gray-800 text-sm">3. <strong>Hit ▶️ </strong> to install the INFO 490 IDE</p><div class="text-center font-bold text-xl"> </div><div class="text-center font-bold text-xl">Jupyter/PyCharm Notes</div><p class="max-w-sm text-gray-800 text-sm text-left">The testing framework does <strong>not work</strong> (at this time) for Jupyter  notebooks or local code development.</p></div></div></div></div><h1 class="section" id="section1">🛑 Words</h1><h2 id="getting-rid-of-the-useless">Getting rid of the useless</h2><p class="new">In the previous lesson on ngrams, we were trying to find the most frequent 
word combinations. Unfortunately, our results left a lot to be desired. Is it 
really useful to know that 'in the' and 'and the' are some of the most 
occurring two word sequences?  Fortunately, with a very simple technique, we 
can make a substantial improvement: removal of stop words.</p><h2 id="stop-considering-these-words">Stop (considering these) Words</h2><p class="new">Usually one of the first things done with text analysis is to remove common 
words that frequently occur across all genres of writing (i.e. across all documents). 
These words are called stop words. Stop words have very little informational 
content. Examples include and, the, of, it, as, may, that, a, an, off, etc. 
You can think of these words as being stopped or dropped from further 
consideration and freeing resources from waiting time with them.  </p><p class="new">There is no definitive list of what constitutes a complete or proper list and 
it usually depends on your situation and needs. In this case, our word 
analysis (and subsequent word clouds) would be improved by removing stop words. 
It's not that interesting to point out that 'the' is the most popular word in the text.  </p><p class="new">The following is a list of 176 common stop words (source: <a href="https://www.ranks.nl/stopwords" target="_blank">https://www.ranks.nl/stopwords</a>). 
Take a look at these words. Are there any words you would remove from this list?<br/>Are there words you would add?</p><pre><code>a
about
above
after
again
against
all
am
an
and
any
are
aren't
as
at
be
because
been
before
being
below
between
both
but
by
can't
cannot
could
couldn't
did
didn't
do
does
doesn't
doing
don't
down
during
each
few
for
from
further
had
hadn't
has
hasn't
have
haven't
having
he
he'd
he'll
he's
her
here
here's
hers
herself
him
himself
his
how
how's
i
i'd
i'll
i'm
i've
if
in
into
is
isn't
it
it's
its
itself
let's
me
more
most
mustn't
my
myself
no
nor
not
of
off
on
once
only
or
other
ought
our
ours
ourselves
out
over
own
same
shan't
she
she'd
she'll
she's
should
shouldn't
so
some
such
than
that
that's
the
their
theirs
them
themselves
then
there
there's
these
they
they'd
they'll
they're
they've
this
those
through
to
too
under
until
up
very
was
wasn't
we
we'd
we'll
we're
we've
were
weren't
what
what's
when
when's
where
where's
which
while
who
who's
whom
why
why's
with
won't
would
wouldn't
you
you'd
you'll
you're
you've
your
yours
yourself
yourselves
callin'
'bout</code></pre><p class="new">The same set of words is available in the data file <code>stopwords.txt</code>.</p><div class="ide code-starter clearfix"><pre><code>import LessonUtil as Util
path = Util.path_for_data('stopwords.txt')
print(open(path, 'r').read())</code></pre></div><p class="new">For some tasks, this list would have to be changed. For example, in 
<strong>sentiment analysis</strong> (identifying and categorizing opinions -- another popular 
NLP (natural language processing) task), it's important <strong>not</strong> to remove
 stop words (mostly adjectives) that might be used to convey some kind of 
 emotion (e.g. well) as well as words that convey negation (can't, don't, etc). 
 There are methods (e.g. tf-idf) that actually identify stop words -- that is 
 words that offer no discerning information. The term frequency inverse document 
 frequency technique will be discussed in the next class.</p><h2 id="hand-in-hand-with-data-cleaning">Hand in Hand with Data Cleaning</h2><p class="new">It's important that whatever cleaning and normalization is done to the data, 
that the same process is applied to stop words as well. Otherwise, it's very 
possible that you will not remove words that should be removed. For example, 
if the words in stopwords.txt were capitalized, but in your normalization 
process you made everything lowercase, no stop words would be removed. 
Similarly, if you removed all apostrophes, stop words like we'd and aren't 
would never be removed. Had we decided to remove all the apostrophes, you 
would also have to remove all the apostrophes in the stop words (a viable decision). 
Otherwise, you will see words like 'ive' and 'im' in your output.  </p><p class="new">The handling of apostrophes can be tricky as well. There are stop words that after 
you remove the apostrophe becomes a different word.  For example, she'd becomes shed, 
we'll becomes well, he'll becomes hell (others include wed, shell, were). </p><p class="new">You could either remove these from your stop word list or decide just to leave 
in the apostrophes. It's important to know how you tokenize and clean your text 
could affect other areas of your analysis. This is one of the reasons why we 
are leaving internal apostrophes alone -- we don't have to clean the stop 
words as well.</p><p class="new">For some types of text analysis the words that convey negation (aren't, can't, 
didn't, doesn't, don't, hadn't, not, can't, cannot, don't, etc) play an 
important part.  Many stop word lists include these words. If your analysis 
never sees negation, you might be building a faulty model. For example, if we 
were doing sentiment analysis or topic modeling, we would leave these words in.</p><h2 id="slippery-slope-of-stop-words">Slippery Slope of Stop Words</h2><p class="new">The caution for having a list of stop words, is that it's easy to get in situation of 
having better analysis by tweaking the stop words. However, this is not a good 
practice if you're trying to build a generic model or pipeline. It's simply 
not scalable to adjust the stop words for every possible text document you are 
processing.  </p><p class="new">There is a temptation to look at your results and add in stop words to get 'better' 
results. For example, the word 'chapter' could be a stop word for this analysis. 
It only occurs as a token to separate chapters so it would be harmless to remove. 
The issue is that if you build a pipeline that processes data automatically, 
you won't be able to customize the stop word list for each input. Similarly, 
the word <code>well</code> appears 427 times and <code>we'll</code> appears 40 times. You would 
have to decide if the connotations and usage of well (interjection vs an adjective, etc) 
affect your analysis before deciding to either remove internal apostrophes (and we'll becomes well) 
or add either as stop words.</p><h2 id="tokenizing-and-cleaning-tom-sawyer">Tokenizing and Cleaning Tom Sawyer</h2><p class="new">In the previous lesson on ngrams, we had a very specific data cleaning stage where 
we removed leading and trailing apostrophes (e.g. 'food' becomes food) but left 
internal apostrophe's alone (e.g. I'm). Luckily this decision will not 
impact the stop words too much. But we will still run the stop words though 
the same data preparation step.</p><p class="new">Since you will be comparing tokens to stop words, you must also normalize the 
stop words to treat words with apostrophes (e.g. I've, I'll, etc) the same as 
you do in <code>split_text_into_tokens</code>.  Had we decided to remove all the apostrophes, 
you would also have to remove all the apostrophes in the stop words (a viable 
decision). Otherwise, you will see words like 'ive' and 'im' in your output.  </p><div class="font-sans container mt-1 mb-4 "><p>🎗Before you go, you should <strong>know</strong>:</p><div class="w-2/3 md:w-2/3"><div class="shadow-md"><div class="tab overflow-hidden border-t bg-green-200"><input class="absolute opacity-0" id="tab-multi-0" name="tabs" type="checkbox"/><label class="block p-3 leading-normal cursor-pointer" for="tab-multi-0"><span> what stop words </span></label><div class="tab-content overflow-hidden border-l-2 bg-orange-300 border-indigo-500 leading-normal"><p class="p-3">No Answer</p></div></div><div class="tab overflow-hidden border-t bg-green-200"><input class="absolute opacity-0" id="tab-multi-1" name="tabs" type="checkbox"/><label class="block p-3 leading-normal cursor-pointer" for="tab-multi-1"><span> why you want to remove them </span></label><div class="tab-content overflow-hidden border-l-2 bg-orange-300 border-indigo-500 leading-normal"><p class="p-3">No Answer</p></div></div><div class="tab overflow-hidden border-t bg-green-200"><input class="absolute opacity-0" id="tab-multi-2" name="tabs" type="checkbox"/><label class="block p-3 leading-normal cursor-pointer" for="tab-multi-2"><span> why it's important to process them the same as you data </span></label><div class="tab-content overflow-hidden border-l-2 bg-orange-300 border-indigo-500 leading-normal"><p class="p-3">No Answer</p></div></div><div class="tab overflow-hidden border-t bg-green-200"><input class="absolute opacity-0" id="tab-multi-3" name="tabs" type="checkbox"/><label class="block p-3 leading-normal cursor-pointer" for="tab-multi-3"><span> understand the issues with stop word removal </span></label><div class="tab-content overflow-hidden border-l-2 bg-orange-300 border-indigo-500 leading-normal"><p class="p-3">No Answer</p></div></div></div></div></div><h1 class="section" id="section2">Lesson Assignment:</h1><h2 id="better-data-better-ngrams">Better Data, Better Ngrams</h2><p class="new">For this lesson, you will use much of your code from the ngrams lesson and build
 two additional functions.</p><p class="new">You will build a simple pipeline that does the following:</p><ul><li>reads in the contents of Huckleberry Finn</li><li>tokenizes the contents into 'words'</li><li>removes all the stop words</li><li>builds a list of all bi-grams</li><li>find the most common bi-grams in the text</li></ul><h2 id="as-mentioned-in-the-ngram-lesson-and-repeated-here">As mentioned in the ngram lesson and repeated here:</h2><p class="new">The above pipeline will be used in other lessons and assignments. It's not 
only important to pass the tests for this lesson, but to understand the workflow. 
We will use this to eventually find characters in literature. Be sure to <strong>TEST</strong> 
each function before moving from one stage to the next. Do NOT attempt 
 to write all the code and then 'run the tests'. You should build your own tests 
 and make sure you understand each function before moving to the next one.</p><h2 id="step-0--copy--paste">Step 0:  Copy &amp; Paste</h2><p class="new">Using another browser tab, go to the ngrams lesson and copy over your working code. 
If you want more programming practice, now's a great time to just <em>reimplement</em> 
the same functions. You might even find a tighter, cleaner solution.  </p><div class="ide code-starter clearfix"><pre><code># feel free to add other functions 
# to help you decompose the problem

def read_text(filename):
  # same solution as Ngrams
  return ""
  
def split_text_into_tokens(text):
  # same solution as Ngrams
  return [] 
  
def bi_grams(tokens):
  # same solution as Ngrams
  return []

def top_n(tokens, n):
  # same solution as Ngrams
  return []</code></pre></div><h2 id="step-1-stop-words">Step 1: Stop Words</h2><p class="new">Create and define a function named <code>load_stop_words</code>.<br/>This function builds a list of stopwords from a filename.  </p><ul><li>You can assume that the file contains one stop word per line.</li><li>If you forgot how to read lines from a file, see the Local I/O lesson.</li></ul><p class="new">We will use the stop words that are given in the file stop_words.txt</p><pre><code>def load_stop_words(filename):
  # read filename and return a list of stopwords</code></pre><p class="new">Note this function will also clean each stop word using the exact same process 
that was done inside your <code>split_text_into_tokens</code> function.</p><p class="new">NOTE: you should also remove surrounding whitespace from each stop word.  </p><p class="new">Although 'stopwords.txt' should not contain any whitespace before or after the words, 
depending on how you read the words in, you could introduce this artifact. It's better to be 
safe and remove surrounding whitespace as well.</p><div class="ide code-starter clearfix"><pre><code>def test_stop_words():
   import LessonUtil as Util
   p = Util.path_for_data('stopwords.txt')
   stop = load_stop_words(p)
   print(stop[0:100])</code></pre></div><h2 id="step-2-cleaning-and-refactoring-code">Step 2: Cleaning and Refactoring code</h2><p class="new">You should now refactor your code so you can remove the code duplication for 
the normalizing step(s). </p><p class="new">What does that mean? </p><p class="new">You should create a function called <code>normalize_token</code> that takes in a word and 
returns the normalized word according to the rules specified in the ngrams lesson 
(i.e. remove leading and trailing apostrophes and whitespace).</p><p class="new">You can now <strong>call</strong> this function in two places!  Once in <code>split_text_into_tokens</code> 
and again in <code>load_stop_words</code>. This is how software development works. When 
you discover a place where code can be reused, you can 'refactor' that code so 
you don't have to duplicate it. </p><ul><li>remove the cleaning code from <code>split_text_into_tokens</code> and place it into 
the <code>normalize_token</code> function. This function takes in a string and returns the normalized, cleaned string.</li><li>in both <code>split_text_into_tokens</code> and <code>load_stop_words</code> call the function you just created.</li><li>once you are done, you should see the following (or something similar) in two places:</li></ul><pre><code>   n = [normalize_token(t) for t in tokens]</code></pre><div class="ide code-starter clearfix"><pre><code>def normalize_token(token):
  return token
  
# Also update 
# def load_stop_words(filename):
#     reads in the contents of filename
#     applies normalization rules to each stop word
#     returns a list of normalized stop words
#     see instructions</code></pre></div><h2 id="step-3--not-stop-words">Step 3:  not stop words</h2><p class="new">Create a function named <code>remove_stop_words(tokens, stoplist)</code>:</p><ul><li><code>tokens</code> is a list of words</li><li><code>stoplist</code> is a list of words</li><li>return a new list of words (in the same order as tokens), but only if the token is not a stop word</li><li>now's a good time to break out a comprehension to solve this using one line of Python.</li></ul><div class="ide code-starter clearfix"><pre><code></code></pre></div><h2 id="step-4-test">Step 4: Test</h2><p class="new">Once this is done the following pipeline should reveal the top 25 bigrams in Huckleberry Finn.  </p><div class="ide code-starter clearfix"><pre><code>def test_pipeline():
    import LessonUtil as Util
    dp = Util.path_for_data('huck.txt')
    sp = Util.path_for_data('stopwords.txt')
    
    text    = read_text(dp)
    stop    = load_stop_words(sp)
    tokens  = split_text_into_tokens(text)
    cleaned = remove_stop_words(tokens, stop)

    # get the top 25 bi-grams w/out stopwords
    grams = bi_grams(cleaned)
    print(top_n(grams, 25))</code></pre></div><p class="new">If the top bi-gram is 'He said', you are most likely done!!!   </p><h2 id="a-few-points-to-ponder">A few points to ponder:</h2><ul><li>Take a look at the returned bi-grams.  Do you see anything interesting?</li><li>Note how you built the functions in such a way that you can reuse this 
code (which you will) in future lessons but on different sources of text.</li></ul><h2 id="a-recap">A recap</h2><p class="new">In this lesson we removed the stop words from the text <strong>BEFORE</strong> we processed 
the text into ngrams. There are many situations (which we will see), where you 
will use the stop words to determine if you want to consider an item for 
further processing. Removing the stopwords like we did in this lesson, 
actually modifies the text order.</p><h2 id="another-quest">Another Quest</h2><p class="new">What two word phrase is the most occurring if <code>normalize_token</code> also did case 
folding (that is made the case the same for all words)?  </p><p class="new">Be sure to remove this additional code before you submit.</p><h1>Test and Submit</h1><p>Once you have finished, you can download your code (via <code>ide.tester</code>) and upload that file to Gradescope (find lesson with tag <strong>DS-Stop</strong>).</p><div class="my-4"><pre><code><strong># to list the tests available</strong><br/>print(ide.tester.list_tests())<br/><strong># to perform a specific test</strong><br/>print(ide.tester.test_functionality('name of test'))<br/><strong># to test your code (either works)</strong><br/>print(ide.tester.test_notebook())<br/>print(ide.tester.test_notebook(verbose=True))<br/><strong># to prepare and download your code</strong><br/>ide.tester.download_solution()</code></pre></div><div class="lesson-footer flex bg-gray-200 justify-center"><div class="lesson-footer-card displaycard bg-blue-200 border-t border-gray-400 max-w-2xl rounded overflow-hidden shadow-lg"><div class="px-6 py-4"><div class="title-text text-center font-bold text-xl">🛑 Words</div><p class="text-center text-gray-800 text-xl">Getting rid of the useless</p><div class="text-center mt-6 text-xl"><i aria-hidden="true" class="fas fa-tags"></i> any questions on Piazza with <span class="font-bold">DS-Stop</span></div><div class="text-gray-700 text-base"> </div><div></div><div></div><div class="flex mt-4 border-t border-solid border-gray-500 justify-around bg-gray-200"><div class="text-gray-700 text-center px-4 m-2 text-sm">🐍  4 D.S.</div><div class="text-gray-700 text-center px-4 m-2 text-sm"><strong>Version:</strong> <!-- -->SP21</div></div><div class="text-gray-700 mt-2 text-center text-sm font-bold">All Rights Reserved Michael Haberman</div><div class="text-gray-700 text-center text-sm">Do not distribute this notebook</div></div></div></div><div> </div><div class="ide code-starter clearfix"><pre><code># print(ide.tester.test_notebook()) 
# print(ide.tester.test_notebook(verbose=True)) 

# once you are ready -- run this 
# ide.tester.download_solution() 
</code></pre></div></div></div></body></html>